package judgestore

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"sync/atomic"

	"github.com/baishancloud/mallard/componentlib/judge/judgestore/filter"
	"github.com/baishancloud/mallard/corelib/expvar"
	"github.com/baishancloud/mallard/corelib/models"
	"github.com/baishancloud/mallard/corelib/zaplog"
)

var (
	// TimeRefactor is refactor to separate metric values into different shard
	// time value is generated by int(unixstamp / 60) * 60
	TimeRefactor int64 = 60

	log = zaplog.Zap("store")
)

var (
	// StoreSizeCounter is counter of file stored files size
	StoreSizeCounter = expvar.NewBase("filestore.size")
	// StoreFilesCounter is counter of file stored files number
	StoreFilesCounter = expvar.NewBase("filestore.file")
)

func init() {
	expvar.Register(StoreFilesCounter, StoreSizeCounter)
}

var (
	writingDir       string
	writingFiles     = make(map[string]*fileHandler)
	writingFilesLock sync.RWMutex
	writingStopFlag  int64
)

// SetDir sets directory to store
func SetDir(dir string) {
	if dir == "" {
		log.Warn("empty-dir")
		return
	}
	writingDir = dir
	log.Info("set-dir", "dir", dir)
	os.MkdirAll(dir, os.ModePerm)
}

// Close closes file manager, sync file handlers to disk and close
func Close() {
	atomic.StoreInt64(&writingStopFlag, 1)
	writingFilesLock.Lock()
	for name, fh := range writingFiles {
		fh.Sync()
		fh.Close()
		log.Debug("fh-close", "name", name)
	}
	writingFilesLock.Unlock()
}

// Write writes values
func Write(value interface{}) {
	if writingDir == "" {
		return
	}
	/*if data, ok := value.([]byte); ok {
		return f.WriteRaw(data)
	}
	if data, ok := value.(json.RawMessage); ok {
		return f.WriteRaw(data)
	}*/
	if data, ok := value.([]*models.Metric); ok {
		WriteMetrics(data)
	}
}

func storeKey(ms *models.Metric) string {
	return fmt.Sprintf("%s_%d", ms.Name, int(ms.Time/TimeRefactor*TimeRefactor))
}

// WriteMetrics writes metrics to log files
func WriteMetrics(metrics []*models.Metric) {
	if writingDir == "" {
		return
	}
	if atomic.LoadInt64(&writingStopFlag) > 0 {
		return
	}
	valuesMap := ressembleMetrics(metrics)
	for key, values := range valuesMap {
		if len(values) == 0 {
			continue
		}
		writingFilesLock.RLock()
		fh := writingFiles[key]
		writingFilesLock.RUnlock()

		if fh == nil {
			writingFilesLock.Lock()
			fileName := filepath.Join(writingDir, key+".log")
			newFh, err := newFileHandler(fileName, values[0].Name)
			if err != nil {
				log.Warn("open-file-error", "file", fileName)
				writingFilesLock.Unlock()
				continue
			}
			log.Info("new", "file", fileName)
			fh = newFh
			writingFiles[key] = newFh
			writingFilesLock.Unlock()
		}
		for _, v := range values {
			b, err := json.Marshal(v)
			if err != nil {
				log.Warn("encode-error", "error", err, "metric", key)
				continue
			}
			if _, err := fh.File().Write(b); err != nil {
				log.Warn("write-file-error", "file", fh.Name(), "value", string(b), "error", err)
				continue
			}
			fh.File().WriteString("\n")
		}
		// fh.Sync()
		fh.Touch()
		// f.Logger.Debug("write-ok", "file", fh.Name(), "len", len(values))
	}
	return
}

var (
	filterLock sync.RWMutex
	filters    filter.ForMetrics
)

// SetFilters sets filters
func SetFilters(f filter.ForMetrics) {
	filterLock.Lock()
	filters = f
	filterLock.Unlock()
}

func ressembleMetrics(metrics []*models.Metric) map[string][]*models.Metric {
	filterLock.RLock()
	defer filterLock.RUnlock()

	tmp := make(map[string][]*models.Metric)
	for _, m := range metrics {
		tmp[m.Name] = append(tmp[m.Name], m)
	}
	for metric, values := range tmp {
		filter := filters[metric]
		if filter == nil {
			continue
		}
		for _, v := range values {
			for tag := range filter.Tags {
				delete(v.Tags, tag)
			}
			for field := range filter.Fields {
				delete(v.Fields, field)
			}
		}
	}

	result := make(map[string][]*models.Metric)
	for _, values := range tmp {
		for _, v := range values {
			key := storeKey(v)
			result[key] = append(result[key], v)
		}
	}
	tmp = nil
	return result
}
